{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qcUXuGHprpGl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q7BCrDmx6jBb",
    "outputId": "1bf73bba-2e9e-4342-8ca9-90cb92e24d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gaussian_box(box_size=5, sigma=1.0, mu=0.0):\n",
    "    \"\"\"\n",
    "    Creates a 2D Gaussian kernel (square) of given size.\n",
    "\n",
    "    Args:\n",
    "        box_size (int): width/height of the square\n",
    "        sigma (float): standard deviation of the Gaussian\n",
    "        mu (float): mean of the Gaussian (center)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 2D array of shape (box_size, box_size)\n",
    "    \"\"\"\n",
    "    # Create a normalized coordinate grid from -1 to 1\n",
    "    x = np.linspace(-1, 1, box_size)\n",
    "    y = np.linspace(-1, 1, box_size)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    \n",
    "    # Compute distance from center\n",
    "    d = np.sqrt(xx**2 + yy**2)\n",
    "    \n",
    "    # Compute Gaussian values\n",
    "    gaussian = np.exp(-((d - mu)**2) / (2 * sigma**2))\n",
    "    return gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UbaaxmrODc9A"
   },
   "outputs": [],
   "source": [
    "class HeatmapDataset(Dataset):\n",
    "    def __init__(self, path, box_size=5, img_size=(64,48), gaussian_box=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path (str): Path to dataset folder containing 'img' and 'ann' subfolders\n",
    "            box_size (int): Size of the Gaussian box for each keypoint\n",
    "            img_size (tuple): Resize images to this size (height, width)\n",
    "            g (np.array): Precomputed Gaussian kernel of shape (box_size, box_size)\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.box_size = box_size\n",
    "        self.img_size = img_size\n",
    "        self.gaussian_box = gaussian_box if gaussian_box is not None else np.ones((box_size, box_size))\n",
    "        self.images, self.heatmaps = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        ann_dir = os.path.join(self.path, 'ann')\n",
    "        img_dir = os.path.join(self.path, 'img')\n",
    "        ann_files = os.listdir(ann_dir)\n",
    "\n",
    "        images, heatmaps = [], []\n",
    "\n",
    "        for name in ann_files:\n",
    "            # Load JSON annotation\n",
    "            with open(os.path.join(ann_dir, name)) as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            points = data.get('objects', [])\n",
    "            if len(points) != 7:\n",
    "                continue  # skip malformed annotations\n",
    "\n",
    "            # Create empty heatmap\n",
    "            h, w = self.img_size\n",
    "            heatmap = np.zeros((7, h, w), dtype=np.float32)\n",
    "\n",
    "            for i, pt in enumerate(points):\n",
    "                coords = np.array(pt['points']['exterior'][0], dtype=int)\n",
    "                cy, cx = coords[1], coords[0]\n",
    "\n",
    "                # Compute box boundaries\n",
    "                ymin = max(0, cy - self.box_size//2)\n",
    "                ymax = min(h-1, cy + self.box_size//2)\n",
    "                xmin = max(0, cx - self.box_size//2)\n",
    "                xmax = min(w-1, cx + self.box_size//2)\n",
    "\n",
    "                # Compute Gaussian slice indices\n",
    "                gymin = ymin - (cy - self.box_size//2)\n",
    "                gymax = gymin + (ymax - ymin + 1)\n",
    "                gxmin = xmin - (cx - self.box_size//2)\n",
    "                gxmax = gxmin + (xmax - xmin + 1)\n",
    "\n",
    "                # Add Gaussian patch and normalize\n",
    "                patch = self.gaussian_box[gymin:gymax, gxmin:gxmax]\n",
    "                patch = patch / patch.sum() if patch.sum() > 0 else patch\n",
    "                heatmap[i, ymin:ymax+1, xmin:xmax+1] = patch\n",
    "\n",
    "            heatmaps.append(torch.from_numpy(heatmap))\n",
    "\n",
    "            # Load image, resize, convert BGR->RGB, normalize\n",
    "            img_path = os.path.join(img_dir, name[:-5])\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.resize(img, (w,h))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_t = torch.from_numpy(img.transpose(2,0,1)).float() / 255.0\n",
    "            images.append(img_t)\n",
    "\n",
    "        return images, heatmaps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.heatmaps[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_bn=True):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.use_bn = use_bn\n",
    "\n",
    "        # Main branch\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=not use_bn)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=not use_bn)\n",
    "        \n",
    "        if use_bn:\n",
    "            self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "            self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "            # Shortcut batch norm only if in/out channels differ\n",
    "            self.bn_shortcut = nn.BatchNorm2d(out_channels) if in_channels != out_channels else nn.Identity()\n",
    "        else:\n",
    "            self.bn1 = self.bn2 = self.bn_shortcut = nn.Identity()\n",
    "        \n",
    "        # Shortcut path\n",
    "        self.shortcut_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=not use_bn)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Main branch\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Shortcut\n",
    "        shortcut = self.shortcut_conv(x)\n",
    "        shortcut = self.bn_shortcut(shortcut)\n",
    "\n",
    "        # Residual addition + ReLU\n",
    "        out = self.relu(out + shortcut)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, base_size=8, num_classes=7, use_bn=True, use_sigmoid=False, use_softmax=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.use_bn = use_bn\n",
    "        self.use_sigmoid = use_sigmoid\n",
    "        self.use_softmax = use_softmax\n",
    "\n",
    "        self.conv = nn.Conv2d(3, base_size, kernel_size=7, padding=3, bias=not use_bn)\n",
    "        self.bn0 = nn.BatchNorm2d(base_size) if use_bn else nn.Identity()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.res1 = ResNetBlock(base_size, base_size*2, use_bn=use_bn)\n",
    "        self.res2 = ResNetBlock(base_size*2, base_size*4, use_bn=use_bn)\n",
    "\n",
    "        self.out = nn.Conv2d(base_size*4, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn0(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.out(x)\n",
    "\n",
    "        if self.use_sigmoid:\n",
    "            x = torch.sigmoid(x)\n",
    "        elif self.use_softmax:\n",
    "            n, c, h, w = x.shape\n",
    "            x = x.view(n, c, -1)         # flatten spatial dims\n",
    "            x = torch.softmax(x, dim=2)  # apply softmax\n",
    "            x = x.view(n, c, h, w)       # reshape back\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, base_size=8, num_classes=7, use_bn=False, use_sigmoid=True, use_softmax=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.use_bn = use_bn\n",
    "        self.use_sigmoid = use_sigmoid\n",
    "        self.use_softmax = use_softmax\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "        # ---------- Encoder ----------\n",
    "        self.conv_d0 = nn.Conv2d(3, base_size, kernel_size=3, padding=1, bias=not use_bn)\n",
    "        self.conv_d1 = nn.Conv2d(base_size, base_size*2, kernel_size=3, padding=1, bias=not use_bn)\n",
    "        self.conv_d2 = nn.Conv2d(base_size*2, base_size*4, kernel_size=3, padding=1, bias=not use_bn)\n",
    "\n",
    "        self.bn_d0 = nn.BatchNorm2d(base_size) if use_bn else nn.Identity()\n",
    "        self.bn_d1 = nn.BatchNorm2d(base_size*2) if use_bn else nn.Identity()\n",
    "        self.bn_d2 = nn.BatchNorm2d(base_size*4) if use_bn else nn.Identity()\n",
    "\n",
    "        # ---------- Decoder ----------\n",
    "        self.upconv1 = nn.Conv2d(base_size*4, base_size*2, kernel_size=3, padding=1, bias=not use_bn)\n",
    "        self.upconv0 = nn.Conv2d(base_size*2, base_size, kernel_size=3, padding=1, bias=not use_bn)\n",
    "\n",
    "        self.bn_up1 = nn.BatchNorm2d(base_size*2) if use_bn else nn.Identity()\n",
    "        self.bn_up0 = nn.BatchNorm2d(base_size) if use_bn else nn.Identity()\n",
    "\n",
    "        self.conv_u1 = nn.Conv2d(base_size*4, base_size*2, kernel_size=3, padding=1, bias=not use_bn)\n",
    "        self.conv_u0 = nn.Conv2d(base_size*2, base_size, kernel_size=3, padding=1, bias=not use_bn)\n",
    "\n",
    "        self.bn_u1 = nn.BatchNorm2d(base_size*2) if use_bn else nn.Identity()\n",
    "        self.bn_u0 = nn.BatchNorm2d(base_size) if use_bn else nn.Identity()\n",
    "\n",
    "        # ---------- Output ----------\n",
    "        self.out = nn.Conv2d(base_size, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        c0 = self.relu(self.bn_d0(self.conv_d0(x)))\n",
    "        c1 = self.relu(self.bn_d1(self.conv_d1(self.max_pool(c0))))\n",
    "        c2 = self.relu(self.bn_d2(self.conv_d2(self.max_pool(c1))))\n",
    "\n",
    "        # Decoder\n",
    "        u1 = self.relu(self.bn_up1(self.upconv1(self.upsample(c2))))\n",
    "        u1 = self.relu(self.bn_u1(self.conv_u1(torch.cat([c1, u1], dim=1))))\n",
    "\n",
    "        u0 = self.relu(self.bn_up0(self.upconv0(self.upsample(u1))))\n",
    "        u0 = self.relu(self.bn_u0(self.conv_u0(torch.cat([c0, u0], dim=1))))\n",
    "\n",
    "        # Output\n",
    "        out = self.out(u0)\n",
    "\n",
    "        if self.use_sigmoid:\n",
    "            out = torch.sigmoid(out)\n",
    "        elif self.use_softmax:\n",
    "            n, c, h, w = out.shape\n",
    "            out = out.view(n, c, -1)          # flatten spatial dims\n",
    "            out = torch.softmax(out, dim=2)   # apply softmax over spatial\n",
    "            out = out.view(n, c, h, w)        # reshape back\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "a-Dr71JI51x_"
   },
   "outputs": [],
   "source": [
    "def model_train(model, train_loader, val_loader, epochs=50):\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    prev_best = float(\"inf\")\n",
    "\n",
    "    train_losses_per_epoch = []\n",
    "    val_losses_per_epoch = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # ---------- TRAIN ----------\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.float().to(device)\n",
    "            y_batch = y_batch.float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            batch_loss = loss_fn(outputs, y_batch)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += batch_loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses_per_epoch.append(avg_train_loss)\n",
    "\n",
    "        # ---------- VALIDATION ----------\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.float().to(device)\n",
    "                y_batch = y_batch.float().to(device)\n",
    "                outputs = model(X_batch)\n",
    "                batch_loss = loss_fn(outputs, y_batch)\n",
    "                val_loss += batch_loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses_per_epoch.append(avg_val_loss)\n",
    "\n",
    "    return model, train_losses_per_epoch, val_losses_per_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gd-UjmSfq896"
   },
   "outputs": [],
   "source": [
    "# create the dataset\n",
    "box_size = 5\n",
    "gaussian_box = make_gaussian_box(box_size=box_size, sigma=1.0, mu=0.0)\n",
    "dataset = HeatmapDataset(path='cones_dataset', box_size=box_size, img_size=(64,48), gaussian_box=gaussian_box)\n",
    "# select rows from the dataset\n",
    "train, test = random_split(dataset, [int(0.9*len(dataset)), len(dataset)-int(0.9*len(dataset))])\n",
    "# create a data loader for train and test sets\n",
    "train_loader = DataLoader(train, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet_base = ResNet(base_size=8, num_classes=7, use_bn=False, use_sigmoid=False, use_softmax=False)\n",
    "UNet_base = UNet(base_size=8, num_classes=7, use_bn=False, use_sigmoid=False, use_softmax=False)\n",
    "models_to_test = [\n",
    "    (\"ResNet_base\", ResNet_base),\n",
    "    (\"UNet_base\", UNet_base),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet_base...\n"
     ]
    }
   ],
   "source": [
    "# Store losses\n",
    "all_train_losses = {}\n",
    "all_val_losses = {}\n",
    "\n",
    "for name, model in models_to_test:\n",
    "    print(f\"Training {name}...\")\n",
    "    trained_model, train_losses, val_losses = model_train(model, train_loader, val_loader, epochs=100)\n",
    "    all_train_losses[name] = train_losses\n",
    "    all_val_losses[name] = val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot (excluding the first epoch)\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for name, _ in models_to_test:\n",
    "    plt.plot(all_val_losses[name][:], label=f\"{name} val loss\")\n",
    "    plt.plot(all_train_losses[name][:], '--', label=f\"{name} train loss\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Comparison\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
